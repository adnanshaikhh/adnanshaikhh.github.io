---
layout: post
title: Love your (ROC) curves
description: A brief explanation about ROC curves
featured: false
---
Ranking models is an important step in deciding whether your model tuning
efforts decidely worked for the best or not. There's two popular metrics used to
score and rank classification algorithms, Receiver Operating Characteristic
(ROC) curves and AUC values.
However, for the
longest time I've found them unintuitive. So my fellow [rubber ducklings](https://en.wikipedia.org/wiki/Rubber_duck_debugging), let's
break down some basic properties.

{: align="middle"}
![roc]

An ROC curve plots the performance of a binary classifier under various
threshold settings. This is the true positive rate (TPR) and false positive rate
(FPR). TPR is the proportion positive correctly classified (TP/P) and the FPR is
calculated by 1-TNR (TN/N). If your classifier predicts “true” more often, it
will have more true positives (good) but also more false positives (bad). If
your classifier is more conservative, predicting “true” less often, it will have
fewer false positives but fewer true positives as well. The ROC curve is a
graphical representation of this tradeoff. An ideal classifier would have a 100%
true positive rate and 0% false positive rate.

When observing the plot, if the plot follows a straight line from lower left to
upper right, then the classifier cannot differentiate between negative and
postive data. If the curve bends to the upper left, then the model can
differentiate the actual positive and negative data. On the contrary, if the
curve bends to the lower right, then you're dealing with a completely wrong
prediction model.

The performance of a classifier model is calculated by calculating the Area
Under Curve (AUC). The AUC score will range between 0 and 1. The higher the AUC
score, the better the model is. Here's some quick facts, a perfect classifier
has an AUC of 1, whereas a random classifier has one of 0.5. A value below 0.5
means that you can invert your outputs to get a better performance so you
probably did something wrong.

### A final note of historical interest[^1]
You may be wondering where the name "Receiver Operating Characteristic" came
from. ROC analysis is part of a field called "Signal Detection Theory" developed
during World War II for the analysis of radar images. Radar operators had to
decide whether a blip on the screen represented an enemy target, a friendly
ship, or just noise. Signal detection theory measures the ability of radar
receiver operators to make these important distinctions. Their ability to do so
was called the Receiver Operating Characteristics. It was not until the 1970's
that signal detection theory was recognized as useful for interpreting medical
test results.

#### Footnotes

[^1]:
    Taken from [University of Nebraska. Medical Center. Department of Internal Medicine](http://gim.unmc.edu/dxtests/effect1.htm)

[^2]:
    In fact, those requests might be more picky, stipulating that the memory
    have a certain
    [alignment](https://en.wikipedia.org/wiki/Data_structure_alignment).

[roc]: /images/roc.png
{: width="80%"}